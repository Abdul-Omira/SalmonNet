{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(pathname):\n",
    "    salmon_data = pd.read_csv(pathname)\n",
    "    salmon_data.head()\n",
    "    salmon_copy = salmon_data\n",
    "    salmon_copy.rename(columns = {\"mo\": \"month\", \"da\" : \"day\", \"fc\" : \"king\"}, \n",
    "          inplace = True)\n",
    "    salmon_copy['date']=pd.to_datetime(salmon_copy[['year','month','day']])\n",
    "    king_data = salmon_copy.filter([\"date\",\"king\"], axis=1)\n",
    "    print(king_data)\n",
    "    king_greater = king_data['date'].apply(pd.Timestamp) >= pd.Timestamp('01/01/1939')\n",
    "    greater_than = king_data[king_greater]\n",
    "    king_all = greater_than[greater_than['date'].apply(pd.Timestamp) <= pd.Timestamp('12/31/2020')]\n",
    "    king_all_copy = king_all\n",
    "    king_all_copy = king_all_copy.reset_index()\n",
    "    king_all_copy = king_all_copy.drop('index', axis=1)\n",
    "    return king_all_copy, king_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  king\n",
      "0     1938-05-01   201\n",
      "1     1938-05-02   227\n",
      "2     1938-05-03    78\n",
      "3     1938-05-04    37\n",
      "4     1938-05-05    29\n",
      "...          ...   ...\n",
      "24729 2021-04-28  2433\n",
      "24730 2021-04-29  4782\n",
      "24731 2021-04-30  4641\n",
      "24732 2021-05-01  2087\n",
      "24733 2021-05-02  2517\n",
      "\n",
      "[24734 rows x 2 columns]\n",
      "            date  king\n",
      "0     1939-01-01     0\n",
      "1     1939-01-02     0\n",
      "2     1939-01-03     0\n",
      "3     1939-01-04     1\n",
      "4     1939-01-05     0\n",
      "...          ...   ...\n",
      "24364 2020-12-25     0\n",
      "24365 2020-12-26     0\n",
      "24366 2020-12-27     0\n",
      "24367 2020-12-28     0\n",
      "24368 2020-12-29     0\n",
      "\n",
      "[24369 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "    chris_path = '/Users/chrisshell/Desktop/Stanford/SalmonData/Use Data/passBonCS.csv'\n",
    "    ismael_path = '/Users/ismaelcastro/Documents/Computer Science/CS Classes/CS230/project/data.csv'\n",
    "    abdul_path = '/Users/abdul/Downloads/SalmonNet/passBonCS.csv'\n",
    "    king_all_copy, king_data= load_data(ismael_path)\n",
    "    print(king_all_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(king_all):\n",
    "    king_training_parse = king_all['date'].apply(pd.Timestamp) <= pd.Timestamp('12/31/2015')\n",
    "    king_training = king_all[king_training_parse]\n",
    "    king_training = king_training.reset_index()\n",
    "    king_training = king_training.drop('index', axis=1)\n",
    "    \n",
    "    king_test_parse = king_all['date'].apply(pd.Timestamp) > pd.Timestamp('12/31/2015')\n",
    "    king_test = king_all[king_test_parse]\n",
    "    king_test = king_test.reset_index()\n",
    "    king_test = king_test.drop('index', axis=1)\n",
    "    \n",
    "    # Normalizing Data\n",
    "    king_training[king_training[\"king\"] < 0] = 0 \n",
    "    king_test[king_test[\"king\"] < 0] = 0\n",
    "    king_train_pre = king_training[\"king\"].to_frame()\n",
    "    king_test_pre = king_test[\"king\"].to_frame()\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    king_train_norm = scaler.fit_transform(king_train_pre)\n",
    "    king_test_norm = scaler.fit_transform(king_test_pre)\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    y_test_not_norm = []\n",
    "    y_train_not_norm = []\n",
    "    \n",
    "    # Set up train and test (train is 180 day series, y val is 181st day etc.)\n",
    "    \n",
    "    for i in range(180,22545): # 30\n",
    "        x_train.append(king_train_norm[i-180:i])\n",
    "        y_train.append(king_train_norm[i])\n",
    "    for i in range(180, 1824):\n",
    "        x_test.append(king_test_norm[i-180:i])\n",
    "        y_test.append(king_test_norm[i])\n",
    "    \n",
    "    # make y_test_not_norm\n",
    "    for i in range(180, 1824):\n",
    "        y_test_not_norm.append(king_test['king'][i])\n",
    "    for i in range(180,22545): # 30\n",
    "        y_train_not_norm.append(king_training['king'][i])\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test, scaler, y_test_not_norm, y_train_not_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, scaler, y_test_not_norm, y_train_not_norm = create_train_test(king_all_copy)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1)).astype(np.float32)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_test_not_norm = np.array(y_test_not_norm)\n",
    "y_test_not_norm = y_test_not_norm.reshape((y_test_not_norm.shape[0], 1))\n",
    "y_train_not_norm = np.array(y_train_not_norm)\n",
    "y_train_not_norm = y_train_not_norm.reshape((y_train_not_norm.shape[0], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(test,predicted):\n",
    "    plt.plot(test, color='red',label='Real Chinook Count')\n",
    "    plt.plot(predicted, color='blue',label='Predicted Chinook Count')\n",
    "    plt.title('Chinook Population Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Chinook Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "def return_rmse(test, predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))\n",
    "    \n",
    "def day_to_year(day_preds):\n",
    "    day_preds = day_preds[183:]\n",
    "    year_preds = []\n",
    "    for i in range(365, len(day_preds), 365):   \n",
    "        salmon_count = np.sum(day_preds[i - 365:i])\n",
    "        year_preds.append(salmon_count)\n",
    "    year_preds = pd.DataFrame(year_preds, columns = [\"Count\"])\n",
    "    return year_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_model(x_train, y_train, x_test, y_test, scaler):\n",
    "    '''\n",
    "    create GRU model trained on X_train and y_train\n",
    "    and make predictions on the X_test data\n",
    "    '''\n",
    "    # The GRU architecture\n",
    "    regressorGRU = Sequential()\n",
    "    # First GRU layer \n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True, input_shape= (x_train.shape[1],1), activation='tanh'))\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(x_train.shape[1],1), activation='tanh'))\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(x_train.shape[1],1), activation='tanh'))\n",
    "    regressorGRU.add(GRU(units=1, activation='tanh'))\n",
    "    regressorGRU.add(Dense(units=1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    regressorGRU.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "    # Fitting to the training set\n",
    "    history = regressorGRU.fit(x_train, y_train, epochs=5, batch_size=150)\n",
    "    \n",
    "    # Predictions \n",
    "    GRU_train_predict = regressorGRU.predict(x_train)\n",
    "    GRU_test_predict = regressorGRU.predict(x_test)\n",
    "\n",
    "    # Descale \n",
    "    GRU_train_predict = scaler.inverse_transform(GRU_train_predict)\n",
    "    y_train = scaler.inverse_transform(y_train)\n",
    "    GRU_test_predict = scaler.inverse_transform(GRU_test_predict)\n",
    "    GRU_test_predict = GRU_test_predict.astype(np.int64)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    return regressorGRU, GRU_train_predict, GRU_test_predict, history, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 35/150 [======>.......................] - ETA: 36s - loss: 0.0018"
     ]
    }
   ],
   "source": [
    "regressorGRU, GRU_train_day, GRU_test_day, history_GRU, y_train, y_test = create_GRU_model(x_train, y_train, x_test, y_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global var for baseline\n",
    "y_test_year = day_to_year(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_year = day_to_year(y_test)\n",
    "bs_chris_path = '/Users/chrisshell/Desktop/Stanford/SalmonData/Use Data/Forecast Data Update.csv'\n",
    "bs_ismael_path = '/Users/ismaelcastro/Documents/Computer Science/CS Classes/CS230/project/forecast_data_17_20.csv'\n",
    "bs_abdul_path = '/Users/abdul/Downloads/SalmonNet/Forecast Data Update.csv'\n",
    "baseline_data = pd.read_csv(bs_ismael_path)\n",
    "traditional = pd.DataFrame(baseline_data[\"Count\"])\n",
    "y_test_year = y_test_year.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_train, GRU_train_day)\n",
    "return_rmse(y_train, GRU_train_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_test, GRU_test_day)\n",
    "return_rmse(y_test, GRU_test_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test RMSE with baseline and GRU\n",
    "return_rmse(y_test_year, traditional)\n",
    "return_rmse(y_test_year, GRU_test_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
