{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baselines</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salmon_data = pd.read_csv(r\"/Users/ismaelcastro/Documents/Computer Science/CS Classes/CS230/project/data.csv\")\n",
    "# salmon_data.head()\n",
    "# salmon_copy = salmon_data # Create a copy for us to work with \n",
    "def load_data(pathname):\n",
    "    salmon_data = pd.read_csv(pathname)\n",
    "    salmon_data.head()\n",
    "    salmon_copy = salmon_data # Create a copy for us to work with \n",
    "    salmon_copy.rename(columns = {\"mo\": \"month\", \"da\" : \"day\", \"fc\" : \"king\"}, \n",
    "          inplace = True)\n",
    "    salmon_copy['date']=pd.to_datetime(salmon_copy[['year','month','day']])\n",
    "#     print(salmon_copy)\n",
    "    king_data = salmon_copy.filter([\"date\",\"king\"], axis=1)\n",
    "    print(king_data)\n",
    "    king_greater = king_data['date'].apply(pd.Timestamp) >= pd.Timestamp('01/01/1939')\n",
    "    greater_than = king_data[king_greater]\n",
    "    king_all = greater_than[greater_than['date'].apply(pd.Timestamp) <= pd.Timestamp('12/31/2020')]\n",
    "    king_all_copy = king_all\n",
    "    king_all_copy = king_all_copy.reset_index()\n",
    "    king_all_copy = king_all_copy.drop('index', axis=1)\n",
    "    return king_all_copy, king_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  king\n",
      "0     1938-05-01   201\n",
      "1     1938-05-02   227\n",
      "2     1938-05-03    78\n",
      "3     1938-05-04    37\n",
      "4     1938-05-05    29\n",
      "...          ...   ...\n",
      "24729 2021-04-28  2433\n",
      "24730 2021-04-29  4782\n",
      "24731 2021-04-30  4641\n",
      "24732 2021-05-01  2087\n",
      "24733 2021-05-02  2517\n",
      "\n",
      "[24734 rows x 2 columns]\n",
      "            date  king\n",
      "0     1939-01-01     0\n",
      "1     1939-01-02     0\n",
      "2     1939-01-03     0\n",
      "3     1939-01-04     1\n",
      "4     1939-01-05     0\n",
      "...          ...   ...\n",
      "24364 2020-12-25     0\n",
      "24365 2020-12-26     0\n",
      "24366 2020-12-27     0\n",
      "24367 2020-12-28     0\n",
      "24368 2020-12-29     0\n",
      "\n",
      "[24369 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "chris_path = '/Users/chrisshell/Desktop/Stanford/SalmonData/Use Data/passBonCS.csv'\n",
    "ismael_path = '/Users/ismaelcastro/Documents/Computer Science/CS Classes/CS230/project/data.csv'\n",
    "abdul_path = '/Users/abdul/Downloads/SalmonNet/passBonCS.csv'\n",
    "king_all_copy, king_data= load_data(ismael_path)\n",
    "print(king_all_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(king_all):\n",
    "    king_training_parse = king_all['date'].apply(pd.Timestamp) <= pd.Timestamp('12/31/2015')\n",
    "    king_training = king_all[king_training_parse]\n",
    "    king_training = king_training.reset_index()\n",
    "    king_training = king_training.drop('index', axis=1)\n",
    "    \n",
    "    king_test_parse = king_all['date'].apply(pd.Timestamp) > pd.Timestamp('12/31/2015')\n",
    "    king_test = king_all[king_test_parse]\n",
    "    king_test = king_test.reset_index()\n",
    "    king_test = king_test.drop('index', axis=1)\n",
    "    print(king_test.shape)\n",
    "    \n",
    "    # Normalizing Data\n",
    "    king_training[king_training[\"king\"] < 0] = 0 \n",
    "    print('max val king_train:')\n",
    "    print(max(king_training['king']))\n",
    "    king_test[king_test[\"king\"] < 0] = 0\n",
    "    print('max val king_test:')\n",
    "    print(max(king_test['king']))\n",
    "    king_train_pre = king_training[\"king\"].to_frame()\n",
    "    king_test_pre = king_test[\"king\"].to_frame()\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    king_train_norm = scaler.fit_transform(king_train_pre)\n",
    "    king_test_norm = scaler.fit_transform(king_test_pre)\n",
    "    print(king_test_norm.shape)\n",
    "    #king_train_norm = (king_training[\"king\"] - np.min(king_training[\"king\"])) / (np.max(king_training[\"king\"]) - np.min(king_training[\"king\"]))\n",
    "    #print(type(king_train_norm))\n",
    "    #king_train_norm = king_train_norm.to_frame()\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    y_test_not_norm = []\n",
    "    y_train_not_norm = []\n",
    "    \n",
    "    # Todo: Experiment with input size of input (ex. 30 days)\n",
    "    \n",
    "    for i in range(180,22545): # 30\n",
    "        x_train.append(king_train_norm[i-180:i])\n",
    "        y_train.append(king_train_norm[i])\n",
    "    for i in range(180, 1824):\n",
    "        x_test.append(king_test_norm[i-180:i])\n",
    "        y_test.append(king_test_norm[i])\n",
    "    \n",
    "    # make y_test_not_norm\n",
    "    for i in range(180, 1824):\n",
    "        y_test_not_norm.append(king_test['king'][i])\n",
    "    for i in range(180,22545): # 30\n",
    "        y_train_not_norm.append(king_training['king'][i])\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test, scaler, y_test_not_norm, y_train_not_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1824, 2)\n",
      "max val king_train:\n",
      "67521\n",
      "max val king_test:\n",
      "32446\n",
      "(1824, 1)\n",
      "(1644, 1)\n",
      "(1644, 1)\n",
      "(22365, 1)\n",
      "(22365, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test, scaler, y_test_not_norm, y_train_not_norm = create_train_test(king_all_copy)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1)).astype(np.float32)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_test_not_norm = np.array(y_test_not_norm)\n",
    "print(y_test.shape)\n",
    "y_test_not_norm = y_test_not_norm.reshape((y_test_not_norm.shape[0], 1))\n",
    "print(y_test_not_norm.shape)\n",
    "y_train_not_norm = np.array(y_train_not_norm)\n",
    "y_train_not_norm = y_train_not_norm.reshape((y_train_not_norm.shape[0], 1))\n",
    "print(y_train_not_norm.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(test,predicted):\n",
    "    plt.plot(test, color='red',label='Real Chinook Count')\n",
    "    plt.plot(predicted, color='blue',label='Predicted Chinook Count')\n",
    "    plt.title('Chinook Population Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Chinook Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "def return_rmse(test, predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1644, 180, 1)\n",
      "(22365, 180)\n"
     ]
    }
   ],
   "source": [
    "x_train_lr = x_train.reshape((x_train.shape[0], x_train.shape[1]))\n",
    "x_test_lr = x_test.reshape((x_test.shape[0], x_test.shape[1]))\n",
    "print(x_test.shape)\n",
    "print(x_train_lr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_model(x_train, y_train, x_test, y_test, scaler):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    train_preds_lr = lr.predict(x_train)\n",
    "    test_preds_lr = lr.predict(x_test)\n",
    "    \n",
    "    #Descale \n",
    "    \n",
    "    train_preds_lr = scaler.inverse_transform(train_preds_lr)\n",
    "    y_train = scaler.inverse_transform(y_train)\n",
    "    test_preds_lr = scaler.inverse_transform(test_preds_lr)\n",
    "    test_preds_lr = test_preds_lr.astype(np.int64)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    return train_preds_lr, test_preds_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean squared error is 1659.7675369964575.\n",
      "The root mean squared error is 3041.7349427380686.\n"
     ]
    }
   ],
   "source": [
    "lr_train, lr_test = create_linear_model(x_train_lr, y_train, x_test_lr, y_test, scaler)\n",
    "\n",
    "return_rmse(y_train, lr_train)\n",
    "return_rmse(y_test, lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List to maintain the different cross-validation scores\n",
    "cross_val_scores_ridge = []\n",
    " \n",
    "# List to maintain the different values of alpha\n",
    "alpha = []\n",
    " \n",
    "# Loop to compute the different values of cross-validation scores\n",
    "for i in range(1, 9):\n",
    "    ridgeModel = Ridge(alpha = i * 0.25)\n",
    "    ridgeModel.fit(x_train, y_train)\n",
    "#     scores = cross_val_score(ridgeModel, X, y, cv = 10)\n",
    "#     avg_cross_val_score = mean(scores)*100\n",
    "#     cross_val_scores_ridge.append(avg_cross_val_score)\n",
    "    alpha.append(i * 0.25)\n",
    " \n",
    "# Loop to print the different values of cross-validation scores\n",
    "for i in range(0, len(alpha)):\n",
    "    print(str(alpha[i])+' : '+str(cross_val_scores_ridge[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
